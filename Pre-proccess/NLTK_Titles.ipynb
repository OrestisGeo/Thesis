{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.read_csv('C:/Users/Orestis/Desktop/1.Diplomatiki/Data/Item Data/imagenewsreel-itemData.csv', delimiter=';', header=None, escapechar='\\\\', quotechar='\\\"')\n",
    "df.columns = ['id','imageId','title','publisher','url','image_url','stemmed','date','article_id']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "imageId        0\n",
       "title         26\n",
       "publisher      0\n",
       "url            0\n",
       "image_url      0\n",
       "stemmed       29\n",
       "date           0\n",
       "article_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "#se poies stiles loipin times kai poses stin kahte mia, 2:titlos,6:stemmed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poies einai oi grammes poy exoun Null sthn 2 stili\n",
    "df[df[2].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51368, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sbinw tis NaN\n",
    "nonull_df = df.dropna(how='any', axis = 0)\n",
    "nonull_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##arithmos me duplicated article id\n",
    "nonull_df.duplicated(subset = 'article_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##akoma enas tropos einai \n",
    "nonull_df.article_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51260, 9), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##afairw tis 108 diploeggrafes twn article_id\n",
    "final_df = nonull_df.drop_duplicates(subset = 'article_id')\n",
    "final_df.shape,type(final_df)\n",
    "###allazei kai to nonull_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#krataw toyw titlous\n",
    "my_titles = final_df['title']\n",
    "len(my_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chri\\xadsto\\xadpher Lauer über die innere Sicher\\xadheit sowie Sinn und Zweck der Video\\xadüber\\xadwa\\xadchung am Südkreuz.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        in schö­ne­berg warf ein junger mann in der ve...\n",
       "1        chri­sto­pher lauer über die innere sicher­hei...\n",
       "2        die wähler in kata­lo­nien haben die spani­sch...\n",
       "3        nach mehr als drei­jäh­riger bauzeit hat an de...\n",
       "4        elek­tro­ni­sche musik hat nun auch myanmar er...\n",
       "5        die spek­ta­ku­läre rück­kehr von jupp heyn­ck...\n",
       "6        yahya a. schnitt seiner frau die kehle durch -...\n",
       "7        jürgen b. harder sitzt in einem hessi­schen ge...\n",
       "8        immer wieder kommt es in schö­ne­berg im kiez ...\n",
       "9        ein 16-jäh­riger und ein 20-jäh­riger stachen ...\n",
       "10       die ermittler kamen dem täter mit einem dna-te...\n",
       "11       mehr­fach wurde der tod des berliner ex-rap­pe...\n",
       "12       nach wohnungs­brand sprang mann aus dem 9. sto...\n",
       "13       zum ersten mal nach der kölner silves­ter­nach...\n",
       "14       in berlin wurde am sonn­abend ein super­markt ...\n",
       "15       der 23-jäh­rige ahmed a. , der seine ehema­lig...\n",
       "16       wer am montag auf die männer geschossen hat un...\n",
       "17       laut polizei reisten erneut große gruppen von ...\n",
       "18       die zahl der straf­an­zeigen nach den sexu­ell...\n",
       "19       mars versorgt sie mit durch­set­zungs­kraft un...\n",
       "20       herthas nach­wuchss­pieler maier (18), mittel­...\n",
       "21       bei dem versuch, die kölner anhänger zu belei­...\n",
       "22       ein notruf aus der innenstadt-diskothek nachtf...\n",
       "23       der italie­ni­sche jour­na­list riccardo ehrma...\n",
       "24       die berliner feuer­wehr rückte am silves­ter­a...\n",
       "25       der toyota century ist bei uns völlig unbe­kan...\n",
       "26       die bundespolizei hat am samstagmittag ein paa...\n",
       "27       die schim­pansen im zoo testen ihren spiel­pla...\n",
       "28       jähr­lich erleiden etwa 270.000 menschen in de...\n",
       "29       am flug­hafen schö­ne­feld wurden zwei persone...\n",
       "                               ...                        \n",
       "51367    take-that-star gary barlow (44) ist als über­r...\n",
       "51368    um falsch­parker von seinem gründ­stück fern­z...\n",
       "51369    miss­glückter über­fall auf einen döner in nie...\n",
       "51370    kleiner tipp: er hatte deutsch­lands nervigste...\n",
       "51371    bisher schafften die schwe­dinnen nur einen ti...\n",
       "51372    was steckt im fach? der zettel mit dem ber-er­...\n",
       "51373                          akt-foto wurde verstei­gert\n",
       "51374                                die schöne first lady\n",
       "51375    fern­seh­mo­de­rator und sportre­porter frank ...\n",
       "51376                                    6. september 2011\n",
       "51377    vor knapp einer woche musste sänger prince ein...\n",
       "51378    unter­nehmer dennis krüger bekam einen groß-au...\n",
       "51379    diskret und voller lust: ehe trotz affäre ist ...\n",
       "51380    er eilt am bosporus von erfolg zu erfolg: nach...\n",
       "51381    ein mann rast durch die fußgän­ger­zone von an...\n",
       "51382    sparen, sparen, sparen – das scheck­heft vom t...\n",
       "51383    in einem gemein­samen antrag von cdu, spd, bün...\n",
       "51384    geschichte und geschichten über und aus porz s...\n",
       "51385    sehn­süchtig wurden mute­math aus new orleans ...\n",
       "51386    play­mobil, barbie oder puzzle: was heute neu ...\n",
       "51387    ein 52-jäh­riger hat eine 32-jäh­rige mitar­be...\n",
       "51388    drei rezepte für die sommer­party. die sind ga...\n",
       "51389    alle news aus dem b.z.-live­ticker: in der nac...\n",
       "51390    roma­nis­ti­k-pro­fessor rein­hard krüger erzä...\n",
       "51391    vieles deutet auf mord hin: in hellers­dorf wu...\n",
       "51392    in der b.z. erzählt talk-gast gloria von thurn...\n",
       "51393    erst besprühten die räuber kameras und fenster...\n",
       "51394    streit­punkt talente: junge spieler kommen bei...\n",
       "51395    bei big brother zeigte sich ex-be­woh­nerin ja...\n",
       "51396    inten­siv­täter nidal r. und sein bruder bei s...\n",
       "Name: title, Length: 51260, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lower case\n",
    "my_titles = my_titles.str.lower()\n",
    "my_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "###thelw na ftiaksw ton pinaka words_list pou periexei oles tis lekseis twn titlwn kahte arthrou ksexwrista\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'): \n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words_list = []\n",
    "stop_words = set(nltk.corpus.stopwords.words(['german']))\n",
    "for x in my_titles:\n",
    "    temp = []\n",
    "    tokens = tokenizer.tokenize(x.replace(u'\\xad', u''))   #afairw ton \\xad xaraktira\n",
    "    tagged_sentence = nltk.pos_tag(tokens)\n",
    "    for word, tag in tagged_sentence:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag:\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        else:\n",
    "            lemma = word\n",
    "        if lemma not in stop_words and len(lemma) > 2 and not lemma.isdigit():   #kanw exclude ta stopwords tis mikres lekseis-arithmous kai tou arithmous se morfi leksis\n",
    "            temp.append(lemma)\n",
    "    words_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51260"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kane save ton pinaka words_list gia na min trexw ton lemmatizer sunexeia\n",
    "import pickle\n",
    "\n",
    "with open(\"lemmatized_titles.pk\", 'wb') as handle:\n",
    "    pickle.dump(words_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51260"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FORTWNW KATEUTHIAN TO WORDS_LIST GIA NA MIN KANW LEMMATIZE KATHE FORA 12 LEPTA!!!!!!\n",
    "import pickle\n",
    "\n",
    "with open('lemmatized_titles.pk', 'rb') as handle:\n",
    "    words_list = pickle.load(handle)\n",
    "len(words_list)  ###prepei na einai o arithmos twn arthrwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import unidecode\n",
    "\n",
    "embedding_voc = {}\n",
    "with open('C:/Users/Orestis/Desktop/cc.de.300.vec', encoding='utf-8') as embedding_file:\n",
    "    for i, l in enumerate(embedding_file.readlines()):\n",
    "        values = l.rstrip().rsplit(' ')     #removing whitespaces kai split\n",
    "        word = unidecode.unidecode(values[0])\n",
    "        embedding_voc[values[0]] = i\n",
    "        # coefs = np.asarray(values[1:], dtype='float32')\n",
    "        # embedding_matrix[i] = coefs\n",
    "# exw se morfi dict to pretrained vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86241"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dimiourgia vocabulary me oles tis lekseis twn titlwn...xrisimopoiw word tokenizer apo nltk\n",
    "# import nltk\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "my_voc = {}\n",
    "counter = 0\n",
    "for words in words_list:    #gia kathe arhtro/titlo\n",
    "    for s in words:         #gia kathe leksi\n",
    "        if s not in my_voc:\n",
    "            my_voc[s] = counter\n",
    "            counter += 1\n",
    "len(my_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_vocabulary.pk\", 'wb') as handle:\n",
    "    pickle.dump(my_voc, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###swzw tin lista me tis tokenized lekseis ana arthro gia na min xreiazetai na to kanw sunexeia\n",
    "# words_list = []my\n",
    "# for x in my_titles:\n",
    "#     words_list.append(tokenizer.tokenize(x.replace(u'\\xad', u'')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 51368\n"
     ]
    }
   ],
   "source": [
    "print(type(words_list), len(words_list))\n",
    "###to megethos tha prepei na einai o arithmos twn arthrwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 32686\n"
     ]
    }
   ],
   "source": [
    "#megistos arithmos leksewn se titlo\n",
    "max_words = 0\n",
    "thesi = 0\n",
    "for k,x in enumerate(words_list):\n",
    "    counter = 0\n",
    "    for words in x:\n",
    "        counter += 1\n",
    "        if counter > max_words:\n",
    "            max_words = counter\n",
    "            thesi = k\n",
    "print(max_words,thesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aufgeregt',\n",
       " 'laufen',\n",
       " 'hunderte',\n",
       " 'ferkel',\n",
       " 'verschläge',\n",
       " 'erst',\n",
       " 'wenige',\n",
       " 'tage',\n",
       " 'alte',\n",
       " 'frischlinge',\n",
       " 'suchen',\n",
       " 'nahrung',\n",
       " 'muttersau',\n",
       " 'eber',\n",
       " 'boris',\n",
       " 'döst',\n",
       " 'derweil',\n",
       " 'stall',\n",
       " 'gut',\n",
       " 'aparte',\n",
       " 'höfe',\n",
       " 'ziehen',\n",
       " 'michael',\n",
       " 'patrick',\n",
       " 'gülden',\n",
       " 'seit',\n",
       " 'frühsommer',\n",
       " 'ferkel',\n",
       " 'heran']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list[32686]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86241"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thelw na dw poses fores emfanizetai i kathe leksi se olous tous titlous twn arthrwn\n",
    "sum_dict = {}\n",
    "\n",
    "for x in words_list:\n",
    "    for word in x:\n",
    "        if word not in sum_dict:\n",
    "            sum_dict[word] = 1\n",
    "        else:\n",
    "            sum_dict[word] = sum_dict[word] + 1\n",
    "\n",
    "len(sum_dict)\n",
    "#idio megethos me to vocabulary ara komple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###twra thelw na kratisw tis 20000 most used lekseis.epomenws tha kanw sort sto sum_dict apo to megalutero key pros to mikrotero kai tha parw\n",
    "# tis prwtes 20000 thesis\n",
    "import operator\n",
    "sorted_list = sorted(sum_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "#to sorted_dict einai mia lista me tuples kai oxi dictionary\n",
    "\n",
    "most_used = []\n",
    "for x in range(0,20000):\n",
    "    most_used.append(sorted_list[x][0])\n",
    "most_used = set(most_used)\n",
    "### epomenws exw mia lista most_used me tis perissotero xrisimopoihmenes lekseis\n",
    "len(most_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(most_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38060"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ksanakanw ena vocabulary gia ton pinaka twn most_used leksewn kai oxi olwn\n",
    "import unidecode\n",
    "\n",
    "counter = 1  \n",
    "mostused_voc={}\n",
    "for x in words_list:\n",
    "    for word in x:\n",
    "        word = unidecode.unidecode(word)\n",
    "        if (word not in mostused_voc) and (word in embedding_voc):   #extra: theloume vocabulary twn most_used leksewn pou uparxoun kai sto\n",
    "            mostused_voc[word] = counter\n",
    "            counter+=1\n",
    "len(mostused_voc)   ###to swzw ws vocabulary_emb.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51260"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista me tous kwdikous tou vocabulary twn pio xrisimopoihmenwn leksewn tou kathe article\n",
    "word_codes = []\n",
    "for x in words_list:\n",
    "    numbers = []\n",
    "    for word in x:\n",
    "        if word in mostused_voc:\n",
    "            numbers.append(mostused_voc[word])  ## me auto ton tropo exoume touw kwsikous twn most_used leksewn kathe arthrou alla oxi thn \n",
    "                                                ## seira emfanisis tous, alla dn mas indiaferei\n",
    "        \n",
    "    for i in range(29 - len(numbers)):\n",
    "        numbers.append(0)       ##o kwdikos tou extra(<PAD>) xaraktira, wste na exoun oloi oi titloi to idio mikos\n",
    "            \n",
    "    word_codes.append(numbers)\n",
    "\n",
    "len(word_codes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apothikeuw ton pinaka word_codes\n",
    "with open(\"word_codes_emb.pk\", 'wb') as handle:\n",
    "    pickle.dump(word_codes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocabulary_emb.pk\", 'wb') as handle:\n",
    "    pickle.dump(mostused_voc, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### twra kanw ena dictionary me value to article_id, kai key ta word_codes...kai meta tha prosthesw san keys kai ta annotations kai tou\n",
    "##publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51260"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_id = final_df['article_id']\n",
    "len(article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"article_id.pk\", 'wb') as handle:\n",
    "    pickle.dump(article_id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_info = {}\n",
    "for ids, codes in zip(article_id,word_codes):\n",
    "    articles_info[ids] = codes\n",
    "\n",
    "len(articles_info)\n",
    "# dict(list(articles_info.items())[0:2])      \n",
    "# articles_info[435053444] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, list)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article_id),type(word_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"articles_info.pk\", 'wb') as handle:\n",
    "    pickle.dump(articles_info, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db8aed01c14a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##dimiourgia pinana embeddings gia tis most used lekseis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mH_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_voc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mH_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "##dimiourgia pinana embeddings gia tis most used lekseis\n",
    "H_embeddings = np.random.rand(len(my_voc)+1,300)\n",
    "H_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kanw load to vocabulary tou Glove\n",
    "import csv\n",
    "\n",
    "glov_voc = {}\n",
    "inputfile = pd.read_csv('C:/Users/Orestis/Desktop/1.Diplomatiki/Glove_Voc/vocab.txt', header=None, sep=' ')\n",
    "c = 0\n",
    "for row in inputfile[0].tolist():\n",
    "    glov_voc[row] = c\n",
    "    c += 1\n",
    "# inf = open('C:/Users/Orestis/Desktop/1.Diplomatiki/Glove_Voc/vocab.txt', 'r')\n",
    "# print(inf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['der', 'und', 'die', 'in', 'von', 'im', 'des', 'den', 'kategorie', 'mit']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = glov_voc.keys()\n",
    "list(a)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51368"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"lemmatized_titles.pk\", 'wb') as handle:\n",
    "    pickle.dump(words_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "test = 'This is a, test tokenization\\ problem.'\n",
    "tokens = word_tokenize(test)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-33ec6cefbb23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnonull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnonull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   3580\u001b[0m         vals = (col.values for name, col in self.iteritems()\n\u001b[0;32m   3581\u001b[0m                 if name in subset)\n\u001b[1;32m-> 3582\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3584\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m         vals = (col.values for name, col in self.iteritems()\n\u001b[1;32m-> 3581\u001b[1;33m                 if name in subset)\n\u001b[0m\u001b[0;32m   3582\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m   1120\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "nonull_df.duplicated(subset = [nonull_df[8], nonull_df[2]])   ### den douleuei..prepei na prosthesw headers sta columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'eight'\n",
    "b = a.isdigit()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
