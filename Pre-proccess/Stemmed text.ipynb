{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/Orestis/Desktop/1.Diplomatiki/Data/Item Data/imagenewsreel-itemData.csv', delimiter=';', header=None, escapechar='\\\\', quotechar='\\\"')\n",
    "df.columns = ['id','imageId','title','publisher','url','image_url','stemmed','date','article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51368, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sbinw tis NaN\n",
    "nonull_df = df.dropna(how='any', axis = 0)\n",
    "nonull_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51260, 9), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = nonull_df.drop_duplicates(subset = 'article_id')\n",
    "final_df.shape,type(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None of [[5, 8]] are in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-16229643ea39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimage_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Orestis/Desktop/1.Diplomatiki/Data/imageUrls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[1;31m# ugly hack for GH #836\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[0;32m    206\u001b[0m                                  \u001b[1;34m\"[{types}] types\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                         raise KeyError(\n\u001b[0;32m   1471\u001b[0m                             u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1472\u001b[1;33m                                 key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1473\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'None of [[5, 8]] are in the [columns]'"
     ]
    }
   ],
   "source": [
    "image_url = final_df.loc[: , [5,8]]\n",
    "image_url\n",
    "image_url.to_csv(\"C:/Users/Orestis/Desktop/1.Diplomatiki/Data/imageUrls\", index= False , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime(df[7])\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = []\n",
    "stemmed = final_df['stemmed']\n",
    "stemmed.shape\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# poios einai o megistos arithmos leksewn stous titlous\n",
    "max_words = 0\n",
    "for x in stemmed:\n",
    "    s = x.split(\";\")\n",
    "    counter = 0\n",
    "    for word in s:\n",
    "        counter+=1\n",
    "    if counter>max_words:\n",
    "        max_words = counter\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc2={} #poses fores emfanizetai h kathe leksi\n",
    "for x in stemmed:\n",
    "    s = x.split(\";\")\n",
    "    for word in s:\n",
    "        if word not in voc2:\n",
    "            voc2[word] = 1\n",
    "        else: \n",
    "            voc2[word] = voc2[word] + 1\n",
    "        \n",
    "len(voc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator #most used lekseis\n",
    "sorted_voc = sorted(voc2.items(), key=operator.itemgetter(1), reverse = True)\n",
    "sorted_voc\n",
    "most_used = []\n",
    "for x in range(0,20000):\n",
    "    most_used.append(sorted_voc[x][0])\n",
    "set(most_used) # to metatrepw apo list se set{} \n",
    "most_used = set(most_used)\n",
    "len(most_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 19999)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimiourgw vocabulary(dictionary) me oles tis lekseis kai tous bazw enan auksanwn arithmo diaforetiko gia kathe leksi\n",
    "counter = 0  \n",
    "vocabulary={}\n",
    "for x in stemmed:\n",
    "    s = x.split(\";\")\n",
    "    for word in s:\n",
    "        if (word not in vocabulary) and (word in most_used):   #extra: theloume vocabulary twn most_used leksewn\n",
    "            #An kaname vocabulary gia oles tis lekseis tha paraleipame to end\n",
    "            vocabulary[word] = counter\n",
    "            counter+=1\n",
    "len(vocabulary), max(vocabulary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"my_vocabulary.pk\", 'wb') as handle:\n",
    "    pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_codes = []   # lista me tous arithmous twn pio xrisimopoihmenwn leksewn tou kathe article\n",
    "for x in stemmed:\n",
    "    numbers = []\n",
    "    s = x.split(\";\")\n",
    "    for word in s:\n",
    "        if word in vocabulary:  #ean i leksi einai stis most_used\n",
    "            numbers.append(vocabulary[word])\n",
    "   # if len(numbers) < 30:\n",
    "    for i in range(30 - len(numbers)):\n",
    "        numbers.append(20000)            ##prosthetw ton kwdiko 20000 gia ton <PAD> xaraktira wste na exoun oloi oi titloi to idio mikos\n",
    "    word_codes.append(numbers)\n",
    "len(word_codes[578])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_codes)\n",
    "#word_codes = np.array(word_codes)\n",
    "#word_codes.shape\n",
    "#word_codes[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0 #posa arthra den periexoun kamia apo tis suxnoteres 20k lekseis\n",
    "for x in word_codes:\n",
    "    if len(x)== 0:\n",
    "        counter+=1\n",
    "print(counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 20000, ...\n",
       "1        [12, 13, 14, 15, 16, 17, 18, 19, 20000, 20000,...\n",
       "2        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 2...\n",
       "3        [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 4...\n",
       "4        [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 5...\n",
       "5        [41, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 6...\n",
       "6        [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 8...\n",
       "7        [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 20000...\n",
       "8        [0, 99, 100, 101, 102, 103, 104, 8, 20000, 200...\n",
       "9        [105, 105, 106, 107, 108, 109, 110, 105, 20000...\n",
       "10       [111, 112, 113, 114, 115, 105, 3, 20000, 20000...\n",
       "11       [116, 117, 7, 118, 119, 120, 121, 122, 123, 7,...\n",
       "12       [127, 128, 3, 129, 130, 131, 20000, 20000, 200...\n",
       "13       [132, 71, 133, 134, 135, 136, 10, 137, 138, 13...\n",
       "14       [7, 143, 144, 145, 35, 146, 147, 148, 149, 150...\n",
       "15       [105, 151, 78, 152, 153, 110, 154, 155, 126, 1...\n",
       "16       [159, 3, 160, 161, 20000, 20000, 20000, 20000,...\n",
       "17       [162, 163, 164, 29, 165, 166, 3, 167, 71, 168,...\n",
       "18       [175, 176, 137, 177, 178, 71, 179, 180, 111, 1...\n",
       "19       [183, 184, 185, 186, 20000, 20000, 20000, 2000...\n",
       "20       [187, 188, 189, 190, 191, 192, 193, 194, 195, ...\n",
       "21       [197, 71, 198, 199, 200, 201, 202, 203, 204, 1...\n",
       "22       [208, 5, 209, 24, 210, 211, 212, 213, 214, 215...\n",
       "23       [219, 220, 221, 222, 223, 224, 225, 20000, 200...\n",
       "24       [7, 211, 226, 227, 228, 229, 214, 230, 231, 23...\n",
       "25       [234, 235, 236, 237, 238, 239, 240, 241, 242, ...\n",
       "26       [243, 244, 245, 246, 247, 248, 249, 250, 251, ...\n",
       "27       [257, 258, 259, 260, 261, 262, 20000, 20000, 2...\n",
       "28       [263, 264, 265, 266, 33, 267, 268, 269, 270, 2...\n",
       "29       [248, 247, 276, 277, 249, 135, 278, 279, 254, ...\n",
       "                               ...                        \n",
       "51367    [17554, 2072, 80, 829, 5115, 1230, 9258, 20000...\n",
       "51368    [14421, 1513, 637, 1332, 223, 20000, 20000, 20...\n",
       "51369    [12154, 146, 4598, 19311, 397, 1397, 1377, 963...\n",
       "51370    [784, 5360, 33, 6726, 3577, 3112, 4138, 3897, ...\n",
       "51371    [471, 4507, 1782, 9140, 852, 20000, 20000, 200...\n",
       "51372    [3149, 12351, 6829, 2330, 4589, 551, 299, 2000...\n",
       "51373    [7745, 20000, 20000, 20000, 20000, 20000, 2000...\n",
       "51374    [1878, 6244, 6245, 20000, 20000, 20000, 20000,...\n",
       "51375    [16679, 14432, 1863, 17367, 711, 186, 7275, 28...\n",
       "51376    [1788, 20000, 20000, 20000, 20000, 20000, 2000...\n",
       "51377    [2952, 70, 415, 7536, 1083, 2684, 19098, 4624,...\n",
       "51378    [2652, 6758, 470, 2001, 16613, 368, 4833, 8468...\n",
       "51379    [1672, 2556, 2411, 4850, 162, 813, 1221, 536, ...\n",
       "51380    [8465, 16920, 693, 693, 42, 341, 631, 1539, 13...\n",
       "51381    [3, 1818, 13942, 17764, 4003, 608, 2282, 92, 1...\n",
       "51382    [1681, 1681, 1681, 663, 2068, 2319, 20000, 200...\n",
       "51383    [466, 1225, 1806, 1359, 11620, 1561, 1807, 330...\n",
       "51384    [2099, 2099, 7524, 3981, 2101, 2099, 14629, 71...\n",
       "51385    [6015, 994, 12584, 7, 3033, 536, 977, 1083, 24...\n",
       "51386    [14377, 387, 290, 1855, 1106, 20000, 20000, 20...\n",
       "51387    [105, 105, 10303, 7321, 2296, 4259, 12729, 110...\n",
       "51388    [42, 6537, 10195, 14125, 20000, 20000, 20000, ...\n",
       "51389    [6599, 6600, 5, 411, 215, 3853, 3, 270, 130, 7...\n",
       "51390    [4537, 470, 1468, 2099, 7763, 330, 5596, 4704,...\n",
       "51391    [75, 13438, 1811, 3632, 6764, 105, 1560, 6736,...\n",
       "51392    [551, 1468, 10618, 10619, 10620, 4589, 11946, ...\n",
       "51393    [132, 4235, 397, 7243, 3409, 5187, 8003, 11705...\n",
       "51394    [19612, 7145, 2, 194, 5036, 18395, 3775, 230, ...\n",
       "51395    [3160, 3161, 306, 3819, 6304, 6008, 4230, 2000...\n",
       "51396    [885, 11853, 606, 2825, 6572, 130, 7279, 3149,...\n",
       "Name: 9, Length: 51368, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prosthetw tous kwdikous twn leksewn sto dataframe\n",
    "df[9]= word_codes\n",
    "df[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "#elegxoume ean ontws den ksefeugei panw apo ton arithmo 20000\n",
    "max_num = 0\n",
    "for x in df[9]:   #to x einai lista\n",
    "    if (len(x)!=0) and (max(x) > max_num):\n",
    "        max_num = max(x)\n",
    "print(max_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 20001) [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(30, 20001) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#ftiaxnw enan one hot vector gia kathe arthro.Rows: oi lekseis kathe arthrou, Columns: Oles oi lekseis tou voc. Tha prepei na exoume 1 opou uparxei h leksi\n",
    "#sto arhtro kai 0 se oles tis upoloipes lekseis.\n",
    "def one_hot_vector_transformation(words):\n",
    "    word_array = np.zeros([len(words),len(vocabulary)+1])\n",
    "    for index,word in enumerate(words):\n",
    "        word_array[index][word] = 1  #epistrefei numpy array\n",
    "    return word_array\n",
    "\n",
    "#H lista one_hot_vectors[] periexei pinakes numpy pou o kathenas antistoixei ston one_hot_vector kathe arthrou\n",
    "one_hot_vectors = []\n",
    "for words in df[9][:10]:\n",
    "    one_hot_vectors.append(one_hot_vector_transformation(words))\n",
    "    # one_hot_vectors += [one_hot_vector_transformation(words)]\n",
    "    print(one_hot_vectors[-1].shape, one_hot_vectors[-1]) \n",
    "     #to one_hot_vectors einai lista epomenws dn exei shape()..omws me to -1 emfanizoume\n",
    "    # mono tin teleutaia eggrafi i opoia einai ena numpy array to opoio einai auto pou epistrefei i sunartisi poy eftiaksa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 300) [[0.18135934 0.41970526 0.16698188 ... 0.53434933 0.05600806 0.53287283]\n",
      " [0.67450917 0.65482662 0.99785198 ... 0.80960158 0.63630658 0.24726745]\n",
      " [0.0634521  0.95788939 0.01054628 ... 0.83774346 0.85347967 0.84625822]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.47322562 0.33590667 0.78651973 ... 0.52065566 0.36745665 0.17580223]\n",
      " [0.58849603 0.81993792 0.99082775 ... 0.85088329 0.65788685 0.50516589]\n",
      " [0.56041381 0.74557034 0.41321277 ... 0.95519717 0.82012821 0.54461639]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.22750931 0.34779419 0.32545079 ... 0.49625177 0.29168358 0.85268501]\n",
      " [0.94465663 0.82957435 0.26971725 ... 0.25910554 0.38404284 0.15352434]\n",
      " [0.51615024 0.54727304 0.69477149 ... 0.88536121 0.19748017 0.27345165]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.35226617 0.78010738 0.77900932 ... 0.43428352 0.13283357 0.5979372 ]\n",
      " [0.31363348 0.76729382 0.248562   ... 0.61910832 0.72930942 0.3906638 ]\n",
      " [0.08246232 0.36151951 0.18524641 ... 0.1065896  0.53237488 0.35981732]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.18159707 0.2482503  0.33232185 ... 0.16910183 0.5599709  0.92080891]\n",
      " [0.15287017 0.00964371 0.45268437 ... 0.62734836 0.15923515 0.696431  ]\n",
      " [0.95669442 0.75237971 0.32237209 ... 0.88416145 0.69324973 0.89019818]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.86143528 0.804626   0.73792882 ... 0.82092404 0.71221533 0.36922681]\n",
      " [0.64861647 0.64044058 0.02011403 ... 0.14228089 0.57696708 0.70350751]\n",
      " [0.15496093 0.01728764 0.88999316 ... 0.91857991 0.40466753 0.81695581]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.70463866 0.0215492  0.10127912 ... 0.4929042  0.45138403 0.85601926]\n",
      " [0.4958428  0.53486438 0.78041367 ... 0.19749551 0.39559802 0.54090997]\n",
      " [0.05300875 0.0372485  0.25345143 ... 0.21926477 0.18102509 0.72867632]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.15943868 0.42763169 0.32574955 ... 0.74986984 0.39315147 0.9836557 ]\n",
      " [0.55130581 0.09708762 0.85084444 ... 0.27655466 0.86062691 0.07149011]\n",
      " [0.08512938 0.01920205 0.21185938 ... 0.88659739 0.18979386 0.68877708]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.18135934 0.41970526 0.16698188 ... 0.53434933 0.05600806 0.53287283]\n",
      " [0.50536454 0.78170778 0.39761784 ... 0.89914567 0.54003807 0.0590352 ]\n",
      " [0.35888031 0.41089629 0.9177231  ... 0.89976132 0.48549147 0.00172106]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n",
      "(30, 300) [[0.17501788 0.54864676 0.47825142 ... 0.51798189 0.53808686 0.3645763 ]\n",
      " [0.17501788 0.54864676 0.47825142 ... 0.51798189 0.53808686 0.3645763 ]\n",
      " [0.12742053 0.16936069 0.81040489 ... 0.99663579 0.76166612 0.3617742 ]\n",
      " ...\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]\n",
      " [0.55391565 0.2155333  0.6243213  ... 0.23246399 0.56436811 0.84316905]]\n"
     ]
    }
   ],
   "source": [
    "#o pinakas autos periexei random times pou tha pollaplasiastoun me tous one_hot_vectors\n",
    "#H_embeddings = np.random.rand(len(vocabulary)+1,300)\n",
    "#print(H_embeddings)\n",
    "def one_hot_vector_transformation(words):\n",
    "    word_array = np.zeros([len(words),len(vocabulary)+1])\n",
    "    for index,word in enumerate(words):\n",
    "        word_array[index][word] = 1  #epistrefei numpy array\n",
    "    return word_array\n",
    "\n",
    "def embedding_transformation(words):\n",
    "    '''\n",
    "    oi parakatw 3 grammes kanoyn to idio me tis apo katw 2\n",
    "    '''\n",
    "    vector = np.zeros((30, 300))\n",
    "    for i, w in enumerate(words):\n",
    "        vector[i] = H_embeddings[w]\n",
    "        \n",
    "    #vector = one_hot_vector_transformation(words)\n",
    "    #vector = vector.dot(H_embeddings)\n",
    "    return vector\n",
    "\n",
    "# H lista embeddings[] periexei pinakes numpy pou o kathenas antistoixei sto apotelesma tou pollaplasiasmou tou H_embedding[] me \n",
    "# ton one_hot_vector kathe arthrou\n",
    "embeddings = []\n",
    "for words in df[9][:10]:\n",
    "    embeddings.append(embedding_transformation(words))\n",
    "    print(embeddings[-1].shape, embeddings[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "#edw thelw na dimiourgisw ena pinaka pou tha exei ta average kathe stilis tis listas embeddings[].Ousiastika anti na exw ena pinaka me embeddings\n",
    "#pou kathe grammh tha antistoixei se kathe leksi, tha exw enan monodiastato pinaka pou tha antistoixei se olh thn protash/titlo.\n",
    "def embedding_transformation(words):\n",
    "    vector = one_hot_vector_transformation(words)\n",
    "    vector = vector.dot(H_embeddings)\n",
    "    return vector\n",
    "\n",
    "def average_vector(X):\n",
    "    average = np.mean(X,axis=0)\n",
    "    return average\n",
    "\n",
    "#edw thelw na dimiourgisw ena pinaka pou tha exei ta average kathe stilis tis listas embeddings[].Ousiastika anti na exw ena pinaka me embeddings\n",
    "#pou kathe grammh tha antistoixei se kathe leksi, tha exw enan monodiastato pinaka pou tha antistoixei se olh thn protash/titlo.\n",
    "average_embeddings = []\n",
    "for words in df[9][:10]:\n",
    "    X = embedding_transformation(words) #epistrefei numpy array [words arthrou x 300]\n",
    "    X = average_vector(X)               #epitrefei ena monodiastato pinaka me tis average times kathe leksis tou arhtrou\n",
    "    print(X.shape)\n",
    "    average_embeddings.append(X)        #apothikeuei ton monodiastato pinaka gia kathe arthro ksexwrista\n",
    "    #print(average_embeddings[-1].shape, average_embeddings[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 150)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_embeddings_2 = np.random.rand(300,150)\n",
    "average_array = np.array(average_embeddings)  # metatrepw thn lista se numpy array gia na parw to .dot()\n",
    "\n",
    "for rows in average_array:\n",
    "    average_embeddings2 = average_array.dot(H_embeddings_2)\n",
    "average_embeddings2.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 1), array([[6223.75865414],\n",
       "        [6261.83218863],\n",
       "        [6211.55453717],\n",
       "        [6170.91443504],\n",
       "        [6146.81914427],\n",
       "        [6040.998535  ],\n",
       "        [6184.37843125],\n",
       "        [6228.9226018 ],\n",
       "        [6273.17550502],\n",
       "        [6323.23281855]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_embeddings_3 = np.random.rand(150,1)\n",
    "for rows in average_embeddings2:\n",
    "    final_average = average_embeddings2.dot(H_embeddings_3)\n",
    "final_average.shape, final_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ALLOS TROPOS-----NTEN NTOULEUEI\n",
    "def h_embeddings_creation(col_num):\n",
    "    row_num = col_num\n",
    "    if col_num == 150:\n",
    "        col_num = 1\n",
    "        embedding_matrix = np.ranmdom.rand(row_num,col_num)\n",
    "        return embedding_matrix\n",
    "    else:\n",
    "        embedding_matrix = np.random.rand(row_num,col_num/2)\n",
    "        return embedding_matrix\n",
    "\n",
    "average_array2 = np.array(average_embeddings)\n",
    "end = 300\n",
    "while end>1:\n",
    "    for rows in average_array:\n",
    "        final_average = average_array2.dot(h_embeddings_creation(end))\n",
    "final_average.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### DEN XREIAZETAI TELIKA\n",
    "data = np.array(embeddings)\n",
    "print((data.shape))\n",
    "data = data.reshape(data.shape[0],1)\n",
    "print((data.shape),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "(30, 300)\n",
      "(29, 100)\n",
      "\n",
      "\n",
      "10 29\n"
     ]
    }
   ],
   "source": [
    "########## CONVOLUTION_2D\n",
    "from scipy import signal\n",
    "\n",
    "#conv_embeddings = []\n",
    "#for i in range(100):\n",
    "#     conv_embeddings[i] = np.random.rand(2,300)\n",
    "#conv_embeddings.shape\n",
    "\n",
    "conv_embeddings = []\n",
    "for i in range(100):\n",
    "    m = np.random.rand(2,300)\n",
    "    conv_embeddings.append(m)\n",
    "    \n",
    "conv_embeddings = np.array(conv_embeddings)       \n",
    "#print(conv_embeddings.shape)\n",
    "\n",
    "#an ithela na efarmosw enan pinaka conv_embedding tha ekana apla: \n",
    "# for article in enumerate(embeddings):\n",
    "#        grad = signal.convolve2d(article, cv, boundary='symm', mode='valid')\n",
    "# Twra omws tha efarmosw pollous pinakes conv_embeddings stis lekseis twn arthrwn opote gia kathe arthro tha exw polla apotelesmata grad. Ena\n",
    "#gia kathe conv_embedding pou efarmozw, dld sto paradeigma 100...Ara 10 arthra x 100 dusdiastatous pinakes grad.\n",
    "final_grad = []\n",
    "for index,article in enumerate(embeddings):\n",
    "    #final_grad.append([])\n",
    "    temp = []\n",
    "    print(article.shape)\n",
    "    for cv in conv_embeddings:\n",
    "    #print(article,article.shape)\n",
    "        grad = signal.convolve2d(article, cv, boundary='symm', mode='valid')\n",
    "        temp.append(grad)\n",
    "    #cancatenate\n",
    "    #temp = np.array(temp)\n",
    "    temp = np.concatenate(temp, axis = 1)\n",
    "    print(temp.shape)\n",
    "    print(\"\\n\")\n",
    "    final_grad.append(temp)\n",
    "        #print(final_grad[-1]) xamos\n",
    "#final_grad_array = np.array(final_grad)\n",
    "print(len(final_grad),len(final_grad[1]))\n",
    "#print(final_grad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a86537480bca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "conv_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_embeddings = []\n",
    "for i in range(100):\n",
    " conv_embeddings[i] = np.random.rand(2,300)\n",
    "conv_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AKURO\n",
    "word_num = []   # lista me tous arithmous twn leksewn tou kathe article me thn xrhsh tou genikou vocabulary, prepei na ftiaksw prwta to voc\n",
    "for x in stemmed:\n",
    "    numbers = []\n",
    "    s = x.split(\";\")\n",
    "    for word in s:\n",
    "        numbers.append(vocabulary[word])\n",
    "    word_num.append(numbers)\n",
    "len(word_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.as_matrix()\n",
    "allpub = data[:, 3]\n",
    "allpub.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17614, 1677, 39234, 13554, 694]\n"
     ]
    }
   ],
   "source": [
    "unpub = []\n",
    "for x in allpub:\n",
    "    if x not in unpub:\n",
    "        unpub.append(x)\n",
    "print(unpub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{694, 1677, 13554, 17614, 39234}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alliws ginete kai etsi \n",
    "#uniquepub = np.unique(allpub) , dld me tin xrisi tis sunartisis np.unique()\n",
    "set(unpub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load('C:/Users/Orestis/Desktop/1.Diplomatiki/Data/Image Data/contestlog2018-01-06IMG/0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 14, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.max(image , axis = (1,2))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51687, (51397,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].max()-df[1].min(), df[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
